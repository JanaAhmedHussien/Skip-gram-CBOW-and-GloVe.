{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "ZIpbQXOWQ-UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy\n",
        "from scipy import spatial"
      ],
      "metadata": {
        "id": "U91hZogkpoJY",
        "outputId": "6de4af7d-38b6-4e35-e8af-d3ce33bdcf3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=[['Nile', 'university', 'Launches', 'New', 'Center', 'for', 'Advanced', 'Materials', 'Research'] ,\n",
        "        [ 'Zewail', 'City', 'Hosts', 'International', 'Conference', 'on', 'Nanotechnology'],\n",
        "         [ \"English\",\" tutorial\",\" fast\",\" track\"],\n",
        "          [\"learning\",\" latent\" \"semantic\",\" indexing\"],\n",
        "          [ \"Book \",\"on\",\" semantic \",\"indexing\"],\n",
        "          [\"Advance\",\" in\",\" structure\" ,\" semantic\",\" indexing\"],\n",
        "          [ \" Analysis\",\" latent\",\" structure\"]]"
      ],
      "metadata": {
        "id": "CW16JF1kRPdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see word university and zewail with these parameters\n",
        "model = Word2Vec(sentences=corpus,\n",
        "                 sg=1,\n",
        "                 vector_size=100,\n",
        "                 window=2,\n",
        "                 min_count=1,\n",
        "                 workers=4,\n",
        "                 epochs=20)\n",
        "word_embedding=model.wv\n",
        "word_embedding['university']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T35G4bMnS-X0",
        "outputId": "5924f880-6444-434e-8304-093a2b9bcedc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-7.2016204e-03,  4.2386102e-03,  2.1765511e-03,  7.4366243e-03,\n",
              "       -4.8679472e-03, -4.5623099e-03, -6.0880096e-03,  3.3228216e-03,\n",
              "       -4.4927052e-03,  8.5110301e-03, -4.2899298e-03, -9.1302861e-03,\n",
              "       -4.8380606e-03,  6.4209444e-03, -6.3859285e-03, -5.2530714e-03,\n",
              "       -7.3045045e-03,  6.0289348e-03,  3.3550442e-03,  2.8277729e-03,\n",
              "       -3.1271365e-03,  6.0399231e-03, -6.1372444e-03, -1.9710981e-03,\n",
              "       -5.9892545e-03, -9.7609882e-04, -2.0193877e-03,  8.4817121e-03,\n",
              "        7.1534021e-05, -8.5746190e-03, -5.4264348e-03, -6.8876650e-03,\n",
              "        2.6962601e-03,  9.4367908e-03, -5.8138352e-03,  8.2605109e-03,\n",
              "        8.5475296e-03, -7.0589269e-03, -8.8844746e-03,  9.4745038e-03,\n",
              "        8.3876690e-03, -4.7019543e-03, -6.7442888e-03,  7.8556892e-03,\n",
              "        3.7722620e-03,  8.0956472e-03, -7.5727818e-03, -9.5360894e-03,\n",
              "        1.5845763e-03, -9.8006297e-03, -4.8739132e-03, -3.4720695e-03,\n",
              "        9.6308179e-03,  8.6150365e-03, -2.8371918e-03,  5.8230269e-03,\n",
              "        8.2444940e-03, -2.2694131e-03,  9.5282784e-03,  7.1646241e-03,\n",
              "        2.0288215e-03, -3.8587993e-03, -5.0690626e-03, -3.0481184e-03,\n",
              "        7.8851944e-03, -6.1765318e-03, -2.9131372e-03,  9.1983909e-03,\n",
              "        3.4518975e-03,  6.0858671e-03, -8.0371527e-03, -7.4548443e-04,\n",
              "        5.5354000e-03, -4.7120196e-03,  7.4753459e-03,  9.3059363e-03,\n",
              "       -3.9920604e-04, -2.0682930e-03, -5.8536371e-04, -5.7965228e-03,\n",
              "       -8.4118694e-03, -1.5148085e-03, -2.5544849e-03,  4.3676421e-03,\n",
              "       -6.8788361e-03,  5.4112179e-03, -6.7331926e-03, -7.8315735e-03,\n",
              "        8.4560579e-03,  8.9085801e-03, -3.4685070e-03,  3.4931395e-03,\n",
              "       -5.7768603e-03, -8.7503064e-03, -5.5091511e-03,  6.7487783e-03,\n",
              "        6.4241164e-03,  9.4479816e-03,  7.0434688e-03,  6.7749303e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_embedding['Zewail']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3qo7fWV4lpa",
        "outputId": "e79d41be-c233-40c6-e3a8-6f1dbf463c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-9.5838290e-03,  8.9442572e-03,  4.1736155e-03,  9.2324046e-03,\n",
              "        6.6619166e-03,  2.9206125e-03,  9.8060593e-03, -4.4073914e-03,\n",
              "       -6.8006385e-03,  4.2157043e-03,  3.7252349e-03, -5.6953533e-03,\n",
              "        9.6899541e-03, -3.5491611e-03,  9.5382053e-03,  8.4251701e-04,\n",
              "       -6.3340636e-03, -1.9754528e-03, -7.3709153e-03, -2.9948321e-03,\n",
              "        1.0523520e-03,  9.4937468e-03,  9.3642334e-03, -6.5935249e-03,\n",
              "        3.4722381e-03,  2.2940065e-03, -2.4962870e-03, -9.2289438e-03,\n",
              "        1.0306720e-03, -8.1657879e-03,  6.3246512e-03, -5.8106384e-03,\n",
              "        5.5349697e-03,  9.8185968e-03, -1.6357357e-04,  4.5323195e-03,\n",
              "       -1.7921660e-03,  7.3654866e-03,  3.9369115e-03, -9.0040220e-03,\n",
              "       -2.3806891e-03,  3.6119388e-03, -1.0940249e-04, -1.1862483e-03,\n",
              "       -1.0487775e-03, -1.6622372e-03,  5.9031800e-04,  4.1524260e-03,\n",
              "       -4.2454940e-03, -3.8344169e-03, -4.4920904e-05,  2.5350120e-04,\n",
              "       -1.5963742e-04, -4.7841403e-03,  4.3067052e-03, -2.1693390e-03,\n",
              "        2.1158094e-03,  6.6349551e-04,  5.9748059e-03, -6.8345438e-03,\n",
              "       -6.8259258e-03, -4.4849110e-03,  9.4500883e-03, -1.5823486e-03,\n",
              "       -9.4260210e-03, -5.3326902e-04, -4.4537000e-03,  6.0055852e-03,\n",
              "       -9.5829116e-03,  2.8691129e-03, -9.2574516e-03,  1.2544339e-03,\n",
              "        6.0131527e-03,  7.3986389e-03, -7.6182839e-03, -6.0656145e-03,\n",
              "       -6.8322439e-03, -7.9218233e-03, -9.4914054e-03, -2.1295096e-03,\n",
              "       -8.6004374e-04, -7.2664507e-03,  6.7862375e-03,  1.1072236e-03,\n",
              "        5.8212597e-03,  1.4732608e-03,  7.9117873e-04, -7.3755071e-03,\n",
              "       -2.1800348e-03,  4.3137972e-03, -5.0688828e-03,  1.1413246e-03,\n",
              "        2.8927100e-03, -1.5348139e-03,  9.9329725e-03,  8.3526755e-03,\n",
              "        2.4225446e-03,  7.1273288e-03,  5.8815498e-03, -5.5604749e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check similarity between two words of this model\n",
        "print(word_embedding.similarity('Zewail', 'university'))"
      ],
      "metadata": {
        "id": "Cld3cAG8piHK",
        "outputId": "54be546e-7fb6-4c9a-a930-93292469d1f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.013847223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# see the word university and zewail with another parameters\n",
        "model2= Word2Vec(sentences=corpus,\n",
        "                 sg=1,\n",
        "                 vector_size=50,\n",
        "                 window=3,\n",
        "                 min_count=1,\n",
        "                 workers=3,\n",
        "                 epochs=20)\n",
        "word_embedding2=model2.wv\n",
        "word_embedding2['university']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9KdkBvg2yto",
        "outputId": "dbf9b1f0-6c9e-436b-e3a3-9de1aeec6821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0173568 , -0.00289396,  0.01895893, -0.01509898, -0.0107162 ,\n",
              "        0.01863313, -0.01794745,  0.00765182,  0.00133088,  0.0133214 ,\n",
              "        0.01662551, -0.00570157, -0.00798463,  0.01779583,  0.00417929,\n",
              "        0.01249788, -0.01889143,  0.01918025, -0.00269662, -0.01210423,\n",
              "        0.00598507, -0.00091322,  0.00941299, -0.00456604, -0.00827568,\n",
              "        0.0045558 ,  0.01670877, -0.00999121,  0.00533736, -0.01598111,\n",
              "       -0.01354669, -0.00093534, -0.01753546,  0.00557888,  0.00319719,\n",
              "       -0.00463938,  0.01000758,  0.01949757,  0.01690854, -0.00376045,\n",
              "        0.0041163 , -0.00800738, -0.01648281,  0.01255591, -0.00389836,\n",
              "       -0.00133241, -0.00354266, -0.00907133,  0.00812342, -0.00854036],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_embedding2['Zewail']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CzuZYEmvAH8",
        "outputId": "5335db2d-dabb-4494-fcdd-0df343eed7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.01429478,  0.00247836, -0.01434699, -0.00446642,  0.00740553,\n",
              "        0.01165351,  0.00241499,  0.0042116 , -0.00825536,  0.01443304,\n",
              "       -0.01260988,  0.00927489, -0.01642556,  0.0040532 , -0.00995054,\n",
              "       -0.00851327, -0.0062288 ,  0.01131429,  0.01156778, -0.0099835 ,\n",
              "        0.0015226 , -0.01697403,  0.01565132,  0.01851664, -0.00547945,\n",
              "        0.00159625,  0.00148611,  0.01096539, -0.01722337,  0.00117391,\n",
              "        0.01375124,  0.00442348,  0.0022523 , -0.01864681,  0.01694557,\n",
              "       -0.01252159, -0.00597442,  0.00698472, -0.00154229,  0.00282404,\n",
              "        0.00356389, -0.01364981, -0.01948766,  0.01808013,  0.01241119,\n",
              "       -0.01382262,  0.00681203,  0.000423  ,  0.00951724, -0.01423455],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check similarity between the same two words of this model\n",
        "print(word_embedding2.similarity('Zewail', 'university'))"
      ],
      "metadata": {
        "id": "CNKiFYuyruRU",
        "outputId": "79c59d40-c055-438d-8451-f8cb85840fd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.17918532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we conclude that the similarity changed when changing model parameter"
      ],
      "metadata": {
        "id": "OEBqDeUdr3CJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see the word university and zewail with another parameters last model\n",
        "model3= Word2Vec(sentences=corpus,\n",
        "                 sg=1,\n",
        "                 vector_size=200,\n",
        "                 window=3,\n",
        "                 min_count=1,\n",
        "                 workers=10,\n",
        "                 epochs=20)\n",
        "word_embedding3=model3.wv\n",
        "word_embedding3['university']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lna6xzXM414Q",
        "outputId": "f6756c89-2088-4e7c-cb53-479eb2f310db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9.7154378e-05,  1.0726685e-03,  5.3282140e-04,  3.7933474e-03,\n",
              "       -2.2108471e-03,  1.6229867e-04,  3.5032677e-03,  1.1258972e-03,\n",
              "        2.1213752e-03,  2.1516390e-03, -6.3282310e-04, -4.1612876e-03,\n",
              "        1.5221280e-03, -4.4365712e-03, -1.3304299e-03, -4.6960223e-03,\n",
              "       -2.3100793e-04, -3.9316458e-03,  3.7069882e-03, -2.4451590e-03,\n",
              "        4.9591498e-03, -4.5161326e-03, -2.1560877e-03,  9.6446334e-04,\n",
              "       -1.4987153e-03,  7.2289171e-04, -1.8404222e-03, -4.4708551e-04,\n",
              "       -2.8636830e-03, -4.9105068e-03,  3.1695992e-03,  1.9182742e-04,\n",
              "        3.2547582e-03, -3.7363141e-03,  1.8317753e-03, -4.9489434e-03,\n",
              "        3.8053656e-03,  2.9622733e-03, -3.0587399e-03,  4.1065300e-03,\n",
              "       -2.7900236e-03, -4.2767995e-03,  7.5014291e-04,  1.5899814e-03,\n",
              "       -4.0483004e-03, -4.4671316e-03,  4.5856615e-03,  8.2188728e-04,\n",
              "        4.3716311e-04,  1.2391162e-03, -1.7535717e-03,  8.6751999e-04,\n",
              "        9.7904145e-04,  4.9030008e-03, -2.8040654e-03,  1.1365133e-03,\n",
              "        3.1535714e-03, -3.3386659e-03, -4.4668950e-03,  4.3281089e-03,\n",
              "        3.4190256e-03, -2.0098870e-03,  2.8711725e-03,  3.9425970e-04,\n",
              "       -2.5053418e-03, -6.7487836e-04, -2.4491823e-03,  3.0673884e-03,\n",
              "        9.8093273e-04, -4.1599697e-03, -7.3130133e-05, -1.3238704e-03,\n",
              "        3.3032631e-03, -5.7284476e-04,  3.8330513e-03,  9.7413780e-04,\n",
              "       -1.9152600e-03,  4.0790793e-03,  1.4747679e-03, -1.9850188e-03,\n",
              "       -2.7999210e-03, -1.5446335e-03, -2.5672852e-03,  1.7200607e-03,\n",
              "       -4.6413173e-03, -2.9104264e-03,  1.6706116e-03,  9.8825098e-05,\n",
              "        2.9975509e-03, -1.8027895e-03, -2.9873847e-06,  1.2375009e-03,\n",
              "        2.7303279e-03,  8.0569385e-04,  4.9080472e-03,  1.8591065e-03,\n",
              "       -3.5910893e-03, -7.0303737e-04, -4.1840649e-03, -2.6635367e-03,\n",
              "       -1.0976988e-03, -4.8538251e-03,  4.6476447e-03,  1.0159839e-03,\n",
              "       -5.8059098e-04, -2.7518535e-03, -4.2549158e-03, -4.9517374e-03,\n",
              "        4.4721924e-03, -1.2497127e-03,  2.2961884e-03, -2.2586822e-03,\n",
              "        4.9790293e-03,  1.8273604e-03,  5.1284669e-04, -2.0220517e-03,\n",
              "        6.0531078e-04, -1.3234019e-03,  3.6753691e-03,  2.2391265e-03,\n",
              "        4.9334107e-04,  1.7415440e-03,  1.8571753e-03, -3.3926875e-03,\n",
              "        4.4653816e-03,  8.6811540e-04, -2.8937322e-03,  4.3283417e-03,\n",
              "       -6.4573885e-04,  4.0935189e-03, -7.5343548e-04,  3.4938259e-03,\n",
              "        1.3631982e-03, -2.1798646e-03, -1.8739641e-03,  4.5958911e-03,\n",
              "        7.9593301e-04, -3.0035055e-03,  1.7481149e-04, -9.8119909e-04,\n",
              "        7.9226255e-04, -3.8586587e-03,  3.6920435e-03,  6.5611303e-04,\n",
              "        3.9375983e-03,  2.2265220e-03, -2.1969359e-03,  1.8763405e-03,\n",
              "       -3.1924248e-04, -4.9281246e-03,  4.1210651e-03,  4.8246868e-03,\n",
              "        4.8266952e-03, -1.8999022e-03, -4.2248117e-03,  2.4138521e-03,\n",
              "       -3.8277404e-03,  4.2660260e-03,  1.3801253e-03,  2.8016686e-03,\n",
              "        3.0582470e-03,  2.3240388e-04, -1.0474473e-03,  3.8658618e-04,\n",
              "        4.9179792e-03, -3.5622681e-03, -7.7622710e-04, -1.1792708e-03,\n",
              "        2.4330039e-03,  3.2250197e-03, -2.0660197e-03,  1.8118345e-03,\n",
              "       -2.2405637e-03,  1.6352332e-03,  4.0842365e-03,  1.8143040e-03,\n",
              "       -2.2864055e-03, -1.5045821e-03,  3.9332025e-03,  4.8020305e-03,\n",
              "        2.9085469e-03, -1.6370177e-03, -9.1264129e-04, -3.1286967e-03,\n",
              "       -2.1477873e-03,  1.6871809e-03, -3.2438731e-03, -3.3080804e-03,\n",
              "        4.0557100e-03,  4.7527310e-03,  4.0702922e-03,  7.5521710e-04,\n",
              "       -4.3979450e-03, -3.7985831e-03,  7.8603922e-04, -4.7638156e-03,\n",
              "       -3.7051046e-03,  1.0120618e-03, -1.4605843e-03, -4.5785052e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_embedding3['Zewail']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpSa3wrh5Gyo",
        "outputId": "568bca57-58ea-4f18-be94-0a1a9802ae03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6.4959883e-04, -4.9037882e-03,  2.2917935e-03, -2.5896516e-04,\n",
              "        3.1677149e-03,  8.9046889e-04, -1.5605321e-03,  3.8840687e-03,\n",
              "        7.7842665e-04,  2.6400712e-05, -2.3048990e-03, -4.2306045e-03,\n",
              "       -3.8795858e-03,  4.3402142e-03, -4.4629779e-03,  4.5186374e-03,\n",
              "       -4.6473546e-03, -1.3958156e-04, -9.5276383e-04, -4.4737379e-03,\n",
              "        4.3219198e-03,  3.3965348e-03,  1.5120113e-03,  2.4207071e-03,\n",
              "        5.7404715e-05,  4.7115628e-03,  3.5124887e-03, -4.9259253e-03,\n",
              "       -2.2188746e-03, -6.4664567e-04,  1.5264029e-03, -2.1630058e-03,\n",
              "        7.3178537e-04, -3.9205845e-03,  1.3861634e-03,  2.3567083e-03,\n",
              "        2.4708644e-03, -1.5825152e-03, -4.2139394e-03, -4.6146456e-03,\n",
              "       -3.5890844e-04, -3.6648663e-03, -3.4145771e-03,  3.0596717e-03,\n",
              "        3.5886222e-03,  1.0527960e-03, -3.9518969e-03, -2.8540373e-03,\n",
              "        4.0292395e-03,  1.9648352e-03, -2.6194761e-03, -3.6977294e-03,\n",
              "        3.8273237e-04,  1.7290132e-03,  1.0431908e-03,  1.5523931e-03,\n",
              "       -2.8093045e-03, -4.9504628e-03, -3.5157434e-03,  1.1049707e-04,\n",
              "        2.3050273e-03,  2.2652820e-03,  9.4389770e-04,  2.5810611e-03,\n",
              "       -6.1835832e-05,  2.0618336e-03, -4.5647928e-03,  3.8559886e-03,\n",
              "        3.0685808e-03,  2.5657376e-03,  3.6040703e-03,  4.2218547e-03,\n",
              "        3.7213153e-04, -8.5034984e-04,  2.6227688e-04, -4.6587647e-03,\n",
              "        4.2046783e-03, -3.1903293e-03,  4.2080781e-03, -2.1222939e-03,\n",
              "        3.2176665e-04, -4.5847287e-03, -4.7809118e-03, -3.9148931e-03,\n",
              "       -3.8652688e-03,  1.8855989e-04, -3.6067765e-03, -2.4763322e-03,\n",
              "       -2.6399484e-03, -2.1421970e-03,  3.5052856e-03,  2.4143816e-03,\n",
              "        4.3432168e-03,  3.5517220e-03, -2.8410952e-03,  3.6233885e-03,\n",
              "       -4.6459115e-03, -1.2929459e-03, -3.8818293e-03,  2.0990493e-03,\n",
              "        9.0159959e-04,  3.5288124e-03,  1.4726900e-03, -3.4908724e-03,\n",
              "        3.8531702e-03, -2.9980319e-03,  4.4960668e-03,  1.4811553e-03,\n",
              "       -2.0099515e-03, -2.3472065e-03, -2.2068729e-03, -3.0754630e-03,\n",
              "        4.6898224e-03, -1.3191915e-03,  3.8864876e-03, -4.8452239e-03,\n",
              "        1.0628637e-03, -6.2589685e-04,  3.7739533e-03, -4.5283567e-03,\n",
              "        3.7182434e-03, -2.5500616e-03, -3.0041963e-03, -2.8316518e-03,\n",
              "       -1.6880458e-03, -1.7045951e-03, -1.6061375e-03, -3.7451021e-03,\n",
              "        3.5432682e-04, -2.8537706e-04, -8.3291170e-04,  1.8732483e-03,\n",
              "       -3.8072066e-03, -1.6183924e-03,  2.5765831e-03,  4.2705964e-03,\n",
              "       -4.9078553e-03,  3.6013152e-03,  2.6524914e-03, -1.9384800e-03,\n",
              "        4.2853006e-03, -4.6124542e-03,  3.6228232e-03,  2.6799268e-03,\n",
              "        6.4288639e-04, -2.6014480e-03, -2.0893512e-03, -1.6808000e-03,\n",
              "        8.0289249e-04,  7.9826423e-04,  3.6974465e-03,  4.9912939e-03,\n",
              "        4.4307895e-03, -1.9989216e-03,  4.8216805e-03, -3.1657633e-04,\n",
              "        2.4363357e-03,  1.2738857e-03, -3.1472859e-04,  1.8317533e-03,\n",
              "       -2.6610927e-03, -2.8775688e-03, -3.8049771e-03,  9.6023764e-04,\n",
              "        3.2637892e-03,  4.4363106e-04,  6.3096808e-04,  1.5803787e-03,\n",
              "        4.0631928e-03, -3.8437829e-03,  1.1321782e-03, -3.7349982e-03,\n",
              "        1.8558213e-03,  4.7515035e-03,  3.7614866e-03,  3.2056668e-03,\n",
              "        4.0048920e-03,  3.2765691e-03,  3.4308250e-03,  4.3458417e-03,\n",
              "       -2.4797339e-03,  4.6034162e-03,  2.5295946e-03, -1.0639747e-03,\n",
              "        4.2472109e-03,  2.5364682e-03,  4.8222840e-03,  1.4171480e-03,\n",
              "        4.9374914e-03,  6.0594763e-04,  4.5689512e-03,  1.7895171e-03,\n",
              "        3.2809947e-03, -1.8124690e-03,  3.3902146e-03,  3.6234504e-03,\n",
              "       -1.0670068e-03, -9.2426146e-04,  1.8014889e-03, -3.5170703e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check similarity between two words of this model\n",
        "print(word_embedding3.similarity('Zewail', 'university'))"
      ],
      "metadata": {
        "id": "y4pz19x_sMml",
        "outputId": "746b9684-3735-4370-d0db-48bfd547c9cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.100933835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we concluded whenever you change the parameters of the model the quality become better or worse according to the parameters as Bigger size values of vector sizerequire more training data, but can lead to better (more accurate) models. Reasonable values are in the tens to hundreds. and also the spped of the output of the vector"
      ],
      "metadata": {
        "id": "t1fbv4ap5M8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**second requirement**: Compare the performance and characteristics of the CBOW model with the Skip-gram model."
      ],
      "metadata": {
        "id": "-OZSGy_y6GkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "speed\n",
        "cbow isfaster\n",
        "cbow: smaller datasets, skip-gram: larger datasets.\n",
        "CBOW smoothes over a lot of the distributional information (by treating an entire context as one observation), useful for smaller datasets. Skip-gram treats each context-target pair as a new observation, and tends to do better when larger datasets"
      ],
      "metadata": {
        "id": "ODIYgwfBGzGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model with cbow\n",
        "model4= Word2Vec(sentences=corpus,\n",
        "                 sg=0,\n",
        "                 vector_size=200,\n",
        "                 window=3,\n",
        "                 min_count=1,\n",
        "                 workers=10,\n",
        "                 epochs=20)\n",
        "word_embedding4=model4.wv\n",
        "word_embedding4['university']\n",
        "# concluding it the same word embeddings for the same words but the cbow is more faster for larger traing model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pALGiFpA6PhB",
        "outputId": "6915c386-2e19-4583-95b9-defbce44c92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9.7154378e-05,  1.0726685e-03,  5.3282140e-04,  3.7933474e-03,\n",
              "       -2.2108471e-03,  1.6229867e-04,  3.5032677e-03,  1.1258972e-03,\n",
              "        2.1213752e-03,  2.1516390e-03, -6.3282310e-04, -4.1612876e-03,\n",
              "        1.5221280e-03, -4.4365712e-03, -1.3304299e-03, -4.6960223e-03,\n",
              "       -2.3100793e-04, -3.9316458e-03,  3.7069882e-03, -2.4451590e-03,\n",
              "        4.9591498e-03, -4.5161326e-03, -2.1560877e-03,  9.6446334e-04,\n",
              "       -1.4987153e-03,  7.2289171e-04, -1.8404222e-03, -4.4708551e-04,\n",
              "       -2.8636830e-03, -4.9105068e-03,  3.1695992e-03,  1.9182742e-04,\n",
              "        3.2547582e-03, -3.7363141e-03,  1.8317753e-03, -4.9489434e-03,\n",
              "        3.8053656e-03,  2.9622733e-03, -3.0587399e-03,  4.1065300e-03,\n",
              "       -2.7900236e-03, -4.2767995e-03,  7.5014291e-04,  1.5899814e-03,\n",
              "       -4.0483004e-03, -4.4671316e-03,  4.5856615e-03,  8.2188728e-04,\n",
              "        4.3716311e-04,  1.2391162e-03, -1.7535717e-03,  8.6751999e-04,\n",
              "        9.7904145e-04,  4.9030008e-03, -2.8040654e-03,  1.1365133e-03,\n",
              "        3.1535714e-03, -3.3386659e-03, -4.4668950e-03,  4.3281089e-03,\n",
              "        3.4190256e-03, -2.0098870e-03,  2.8711725e-03,  3.9425970e-04,\n",
              "       -2.5053418e-03, -6.7487836e-04, -2.4491823e-03,  3.0673884e-03,\n",
              "        9.8093273e-04, -4.1599697e-03, -7.3130133e-05, -1.3238704e-03,\n",
              "        3.3032631e-03, -5.7284476e-04,  3.8330513e-03,  9.7413780e-04,\n",
              "       -1.9152600e-03,  4.0790793e-03,  1.4747679e-03, -1.9850188e-03,\n",
              "       -2.7999210e-03, -1.5446335e-03, -2.5672852e-03,  1.7200607e-03,\n",
              "       -4.6413173e-03, -2.9104264e-03,  1.6706116e-03,  9.8825098e-05,\n",
              "        2.9975509e-03, -1.8027895e-03, -2.9873847e-06,  1.2375009e-03,\n",
              "        2.7303279e-03,  8.0569385e-04,  4.9080472e-03,  1.8591065e-03,\n",
              "       -3.5910893e-03, -7.0303737e-04, -4.1840649e-03, -2.6635367e-03,\n",
              "       -1.0976988e-03, -4.8538251e-03,  4.6476447e-03,  1.0159839e-03,\n",
              "       -5.8059098e-04, -2.7518535e-03, -4.2549158e-03, -4.9517374e-03,\n",
              "        4.4721924e-03, -1.2497127e-03,  2.2961884e-03, -2.2586822e-03,\n",
              "        4.9790293e-03,  1.8273604e-03,  5.1284669e-04, -2.0220517e-03,\n",
              "        6.0531078e-04, -1.3234019e-03,  3.6753691e-03,  2.2391265e-03,\n",
              "        4.9334107e-04,  1.7415440e-03,  1.8571753e-03, -3.3926875e-03,\n",
              "        4.4653816e-03,  8.6811540e-04, -2.8937322e-03,  4.3283417e-03,\n",
              "       -6.4573885e-04,  4.0935189e-03, -7.5343548e-04,  3.4938259e-03,\n",
              "        1.3631982e-03, -2.1798646e-03, -1.8739641e-03,  4.5958911e-03,\n",
              "        7.9593301e-04, -3.0035055e-03,  1.7481149e-04, -9.8119909e-04,\n",
              "        7.9226255e-04, -3.8586587e-03,  3.6920435e-03,  6.5611303e-04,\n",
              "        3.9375983e-03,  2.2265220e-03, -2.1969359e-03,  1.8763405e-03,\n",
              "       -3.1924248e-04, -4.9281246e-03,  4.1210651e-03,  4.8246868e-03,\n",
              "        4.8266952e-03, -1.8999022e-03, -4.2248117e-03,  2.4138521e-03,\n",
              "       -3.8277404e-03,  4.2660260e-03,  1.3801253e-03,  2.8016686e-03,\n",
              "        3.0582470e-03,  2.3240388e-04, -1.0474473e-03,  3.8658618e-04,\n",
              "        4.9179792e-03, -3.5622681e-03, -7.7622710e-04, -1.1792708e-03,\n",
              "        2.4330039e-03,  3.2250197e-03, -2.0660197e-03,  1.8118345e-03,\n",
              "       -2.2405637e-03,  1.6352332e-03,  4.0842365e-03,  1.8143040e-03,\n",
              "       -2.2864055e-03, -1.5045821e-03,  3.9332025e-03,  4.8020305e-03,\n",
              "        2.9085469e-03, -1.6370177e-03, -9.1264129e-04, -3.1286967e-03,\n",
              "       -2.1477873e-03,  1.6871809e-03, -3.2438731e-03, -3.3080804e-03,\n",
              "        4.0557100e-03,  4.7527310e-03,  4.0702922e-03,  7.5521710e-04,\n",
              "       -4.3979450e-03, -3.7985831e-03,  7.8603922e-04, -4.7638156e-03,\n",
              "       -3.7051046e-03,  1.0120618e-03, -1.4605843e-03, -4.5785052e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check similarity between two words of 2 models\n",
        "print(\"The similarity between zewail and university of skip and gram model,\",word_embedding3.similarity('Zewail', 'university'))\n",
        "print(\"The similarity between zewail and university of Cbow,\",word_embedding4.similarity('Zewail', 'university'))"
      ],
      "metadata": {
        "id": "VHQJYPGbv19r",
        "outputId": "666822d3-bcb7-4a2b-e769-fd3fb209b748",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The similarity between zewail and university of skip and gram model, 0.100933835\n",
            "The similarity between zewail and university of Cbow, 0.10092539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check most similar words in the 2 models\n",
        "print(\"The most similar words for university of skip and gram model,\",word_embedding3.most_similar( 'university'))\n",
        "print(\"The most similar words for university of Cbow,\",word_embedding4.most_similar( 'university'))"
      ],
      "metadata": {
        "id": "xU_hTiSZpgsV",
        "outputId": "b7b2c2ed-b32e-4fe0-b10a-302fcf9a52fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar words for university of skip and gram model, [('Advanced', 0.13283511996269226), (' Analysis', 0.11319436877965927), ('City', 0.1110934317111969), ('Zewail', 0.10093383491039276), ('Launches', 0.09551874548196793), (' structure', 0.09152578562498093), (' track', 0.0889725387096405), ('indexing', 0.06350592523813248), (' indexing', 0.060891907662153244), (' tutorial', 0.05075513571500778)]\n",
            "The most similar words for university of Cbow, [('Advanced', 0.13283036649227142), (' Analysis', 0.11308196187019348), ('City', 0.11116836965084076), ('Zewail', 0.10092538595199585), ('Launches', 0.0954921543598175), (' structure', 0.09137345850467682), (' track', 0.08896512538194656), ('indexing', 0.06352829188108444), (' indexing', 0.06088348478078842), (' tutorial', 0.050732824951410294)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair"
      ],
      "metadata": {
        "id": "hYZTW_3ujkSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2d2219-f0ef-4869-916a-edd15fa2422a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flair in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: boto3>=1.20.27 in /usr/local/lib/python3.10/dist-packages (from flair) (1.34.96)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from flair) (0.3.5)\n",
            "Requirement already satisfied: conllu>=4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.5.3)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.14)\n",
            "Requirement already satisfied: ftfy>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from flair) (6.2.0)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (5.1.0)\n",
            "Requirement already satisfied: gensim>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.3.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from flair) (0.20.3)\n",
            "Requirement already satisfied: janome>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from flair) (0.5.0)\n",
            "Requirement already satisfied: langdetect>=1.0.9 in /usr/local/lib/python3.10/dist-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.9.4)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (3.7.1)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.10/dist-packages (from flair) (10.1.0)\n",
            "Requirement already satisfied: mpld3>=0.3 in /usr/local/lib/python3.10/dist-packages (from flair) (0.5.10)\n",
            "Requirement already satisfied: pptree>=3.1 in /usr/local/lib/python3.10/dist-packages (from flair) (3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from flair) (0.2.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from flair) (2023.12.25)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.2)\n",
            "Requirement already satisfied: segtok>=1.5.11 in /usr/local/lib/python3.10/dist-packages (from flair) (1.5.11)\n",
            "Requirement already satisfied: sqlitedict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.1.0)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair) (0.9.0)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.66.2)\n",
            "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (0.4.0)\n",
            "Requirement already satisfied: transformers[sentencepiece]<5.0.0,>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.40.1)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from flair) (1.26.18)\n",
            "Requirement already satisfied: wikipedia-api>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from flair) (0.6.0)\n",
            "Requirement already satisfied: semver<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flair) (3.0.2)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.96 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair) (1.34.96)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (2.31.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (0.1.99)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->flair) (1.14.1)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (3.14.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.2.0->flair) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.2.0->flair) (6.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (24.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect>=1.0.9->flair) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (3.1.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mpld3>=0.3->flair) (3.1.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (3.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.8,>=1.5.0->flair) (12.4.127)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.4.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (3.20.3)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.29.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mpld3>=0.3->flair) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.2->flair) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.2->flair) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.2->flair) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (5.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.embeddings import WordEmbeddings\n",
        "from flair.data import Sentence\n",
        "# init embedding\n",
        "glove_embedding = WordEmbeddings('glove')"
      ],
      "metadata": {
        "id": "2U-3S1d7jiI2",
        "outputId": "ee999b18-1221-4ec8-f2e9-42fb5b1d11f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-02 18:59:08,625 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmph3tvwf3r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 153M/153M [00:08<00:00, 18.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-02 18:59:17,871 copying /tmp/tmph3tvwf3r to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-02 18:59:18,179 removing temp file /tmp/tmph3tvwf3r\n",
            "2024-05-02 18:59:18,739 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmpuf4qimm0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:02<00:00, 9.61MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-02 18:59:21,494 copying /tmp/tmpuf4qimm0 to cache at /root/.flair/embeddings/glove.gensim\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-02 18:59:21,519 removing temp file /tmp/tmpuf4qimm0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create sentence with rose as a flower\n",
        "sentence1 = Sentence('She picked a beautiful rose from the garden')\n",
        "\n",
        "print(sentence1)\n",
        "print(sentence1.tokens)\n",
        "\n",
        "print(sentence1[4])"
      ],
      "metadata": {
        "id": "oDzTIAVZnrKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1085ff-f7e6-4eac-964a-f49f8a7c11ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence[8]: \"She picked a beautiful rose from the garden\"\n",
            "[Token[0]: \"She\", Token[1]: \"picked\", Token[2]: \"a\", Token[3]: \"beautiful\", Token[4]: \"rose\", Token[5]: \"from\", Token[6]: \"the\", Token[7]: \"garden\"]\n",
            "Token[4]: \"rose\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embedding.embed(sentence1)\n",
        "\n",
        "for token in sentence1:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVZrBgwAKVkQ",
        "outputId": "4c3cc747-0905-4373-cb75-7852ce8c8631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[0]: \"She\"\n",
            "tensor([ 0.3144,  0.1531,  0.1826, -0.0959,  0.1320,  0.4428, -0.1401,  0.8488,\n",
            "         0.5705,  0.2021,  0.3575,  0.2790,  0.2424,  0.5929,  0.0709, -0.2236,\n",
            "         0.2905,  0.2584, -0.5239,  0.2074, -0.1903,  0.0785,  0.3739,  0.1341,\n",
            "         0.6007,  0.7033, -0.5381, -1.5178,  0.4962, -0.3139, -0.4069,  1.1136,\n",
            "         0.4728,  0.3203, -0.0774,  0.2923, -0.2867,  0.1330,  0.1037, -0.2659,\n",
            "        -1.0749, -0.1974,  0.1176, -0.5536, -0.2697, -0.0694, -0.0873, -0.6109,\n",
            "         0.7917, -0.4573, -0.2104, -0.4465,  1.0217,  1.4455, -0.1559, -2.9029,\n",
            "        -0.1445, -0.2267,  0.8572,  1.1399,  0.1820,  1.0707, -0.3531,  0.1442,\n",
            "         0.6392, -0.3528,  0.7269,  0.3061,  0.2623,  0.4319,  0.1371, -0.1222,\n",
            "         0.1147,  0.2121,  0.2266,  0.8510, -0.1074, -0.4954, -0.8858, -0.5439,\n",
            "         0.1720, -0.0254, -0.0805,  0.3384, -1.9701, -1.4076, -0.0744, -0.2123,\n",
            "        -0.6591, -0.6036,  0.0125, -0.7423,  0.9570,  0.4106, -0.5335,  0.6575,\n",
            "        -0.5649, -0.0427,  0.0610,  0.7434])\n",
            "Token[1]: \"picked\"\n",
            "tensor([ 0.0938, -0.0253,  0.1572, -1.0363,  0.5855, -0.1172,  0.5176,  0.1274,\n",
            "        -0.3623, -0.1980,  0.2366,  0.1843,  0.2650, -0.2121,  0.2800, -0.2963,\n",
            "         0.2729,  0.0497, -0.1919,  0.1165,  0.1898,  0.2876,  0.3574, -0.1193,\n",
            "         0.0723, -0.1728, -0.1648,  0.0944,  0.1620,  0.0499,  0.0835,  0.4260,\n",
            "         0.0555,  0.4575,  0.3921, -0.1353, -0.4367, -0.0124, -0.1049,  0.1706,\n",
            "        -0.5471, -0.6072,  0.5237, -0.1806,  0.0214,  0.1199, -0.3385,  0.1053,\n",
            "         0.2587, -0.7548,  0.0297,  0.0433, -0.0432,  0.6918, -0.0497, -1.5961,\n",
            "        -0.6768,  0.5359,  0.9198,  0.8062,  0.0429,  0.9780, -0.4367,  0.4820,\n",
            "         0.1053, -0.1418,  0.1558,  0.3282,  0.0318,  0.3795, -0.2546,  0.2142,\n",
            "         0.1430, -0.3247, -0.1936,  0.5433, -0.6798,  0.1880,  0.0836,  0.0758,\n",
            "         0.3008, -0.0947, -0.7244, -0.4038, -0.7771, -1.1422,  0.4369,  0.2042,\n",
            "        -0.4016, -0.1739, -0.2788,  0.0385,  0.0337, -0.0960, -0.8680,  0.0221,\n",
            "        -0.2031,  0.5952,  0.2309,  0.2672])\n",
            "Token[2]: \"a\"\n",
            "tensor([-0.2709,  0.0440, -0.0203, -0.1740,  0.6444,  0.7121,  0.3551,  0.4714,\n",
            "        -0.2964,  0.5443, -0.7229, -0.0048,  0.0406,  0.0432,  0.2973,  0.1072,\n",
            "         0.4016, -0.5366,  0.0334,  0.0674,  0.6456, -0.0855,  0.1410,  0.0945,\n",
            "         0.7495, -0.1940, -0.6874, -0.4174, -0.2281,  0.1200, -0.4900,  0.8094,\n",
            "         0.0451, -0.1190,  0.2016,  0.3928, -0.2012,  0.3135,  0.7530,  0.2591,\n",
            "        -0.1157, -0.0293,  0.9350, -0.3607,  0.5242,  0.2371,  0.5271,  0.2287,\n",
            "        -0.5196, -0.7935, -0.2037, -0.5019,  0.1875,  0.9428, -0.4483, -3.6792,\n",
            "         0.0442, -0.2675,  2.1997,  0.2410, -0.0334,  0.6955, -0.6447, -0.0072,\n",
            "         0.8957,  0.2001,  0.4649,  0.6193, -0.1066,  0.0869, -0.4623,  0.1826,\n",
            "        -0.1585,  0.0208,  0.1937,  0.0634, -0.3167, -0.4818, -1.3848,  0.1367,\n",
            "         0.9686,  0.0500, -0.2738, -0.0357, -1.0577, -0.2447,  0.9037, -0.1244,\n",
            "         0.0808, -0.8340,  0.5720,  0.0889, -0.4253, -0.0183, -0.0800, -0.2858,\n",
            "        -0.0109, -0.4923,  0.6369,  0.2364])\n",
            "Token[3]: \"beautiful\"\n",
            "tensor([-0.1817,  0.4976,  0.4633,  0.2251,  0.4638,  0.7006, -0.5515,  0.7915,\n",
            "        -0.1858,  0.1975,  0.1988,  0.0904,  0.0268,  0.0369,  0.2522,  0.3088,\n",
            "         0.3316,  0.2714, -0.1281,  1.1721, -0.0730,  0.3490,  0.1116, -0.3606,\n",
            "         0.5963,  0.4242, -0.6990, -0.1977, -0.3560, -0.2314, -0.3850, -0.1267,\n",
            "         0.7712, -0.3740,  0.5964, -0.2442, -0.2539, -0.0659,  0.2104, -0.8343,\n",
            "         0.2860, -0.0227,  0.0675,  0.0888,  0.2342,  0.2048,  0.0854,  0.5539,\n",
            "         0.3415, -0.0955, -0.1929, -0.5526,  1.0229,  0.3866, -0.2425, -2.3519,\n",
            "         0.4356,  1.1172,  0.7736, -0.7377, -0.3530,  1.6699, -0.6395, -0.3924,\n",
            "         0.5645, -0.2787,  0.9252, -0.1400, -0.0962, -1.1242,  0.4903,  0.3692,\n",
            "         0.4119, -0.0382,  0.8412,  0.2462,  0.0818,  0.0748,  0.4465, -0.1942,\n",
            "         0.0134,  0.3771,  0.2328,  0.2573, -0.8593, -0.3665, -0.0608, -0.4635,\n",
            "        -0.2119, -0.5065,  0.3340, -0.2409,  0.5626, -0.0414, -1.0032,  0.1337,\n",
            "        -1.8932, -0.8188, -0.4412,  0.5139])\n",
            "Token[4]: \"rose\"\n",
            "tensor([ 1.0937,  0.8214, -0.1852,  0.0786,  0.4147, -0.6426,  0.4255, -0.4695,\n",
            "        -0.4304, -0.4947, -0.0741, -0.4623, -0.3771, -0.2303,  0.6403, -0.5667,\n",
            "        -0.2091,  0.1569,  0.1502,  0.4576,  1.1152, -0.1295,  0.6497,  1.2699,\n",
            "         0.4033, -0.2435,  0.1815, -0.6812,  0.0251, -0.2500,  0.2702, -0.3044,\n",
            "         0.0668,  0.0367, -0.0932,  1.1323,  1.0154,  0.0239,  0.2471, -0.2042,\n",
            "         0.0470, -1.1112, -0.2564, -0.3373,  0.3545,  0.6022, -0.6253,  0.4094,\n",
            "         0.5817, -1.9538,  0.0367, -0.2600,  0.5758,  1.3510, -0.3376, -1.7692,\n",
            "        -0.7869,  0.1131,  1.3780,  0.7508,  0.4910, -0.2592, -0.7883,  0.1579,\n",
            "        -0.9344, -0.0443,  0.5513,  0.4390,  1.4439,  0.5425, -0.2027,  0.2897,\n",
            "        -0.4371,  0.1773, -0.3873,  0.3120, -0.0888,  0.3427, -0.6611,  0.1731,\n",
            "         0.2724,  0.6642, -0.2498, -0.4517, -0.4424, -0.7880,  0.3900, -0.6051,\n",
            "         1.1775,  0.6952,  0.3008, -0.0824, -0.4513,  0.4200, -1.2335,  0.4458,\n",
            "         0.1206, -0.3677,  0.1822,  0.3347])\n",
            "Token[5]: \"from\"\n",
            "tensor([ 3.0731e-01,  2.4737e-01,  6.8231e-01, -5.2367e-01,  4.4053e-01,\n",
            "         4.2044e-01,  2.5140e-04,  1.5265e-01, -6.1363e-01,  2.2631e-01,\n",
            "         8.3071e-02,  7.0425e-02,  1.7683e-02,  5.6807e-01,  1.0067e+00,\n",
            "        -4.6206e-01,  4.4524e-01, -5.0984e-01, -4.2985e-01,  1.9935e-01,\n",
            "         2.2729e-01,  5.1662e-01,  5.6282e-01,  4.1282e-01,  1.7742e-01,\n",
            "        -1.5694e-01, -1.1505e-01, -3.8050e-01,  4.7440e-01, -1.6686e-01,\n",
            "         2.3153e-01,  6.3698e-02, -1.0716e-01, -2.6848e-01, -4.2665e-01,\n",
            "         5.2237e-01,  9.5376e-02,  6.4020e-01, -5.2221e-01, -1.3856e-01,\n",
            "        -9.8307e-01, -3.5320e-01, -5.2161e-01,  1.1277e-01,  3.1634e-01,\n",
            "         1.3297e-01, -4.9571e-02, -1.3785e-01,  1.1317e-01, -5.0644e-01,\n",
            "         3.8373e-01,  3.6698e-01,  3.9106e-01,  9.8143e-01, -5.4410e-01,\n",
            "        -2.4640e+00, -6.8383e-01, -9.6243e-01,  2.2017e+00,  5.6643e-01,\n",
            "        -4.9410e-02,  1.3093e+00, -4.0073e-01,  8.3530e-01,  1.7440e-01,\n",
            "         4.4926e-02,  5.4118e-01, -1.1038e-01,  3.8200e-01,  1.5369e-01,\n",
            "        -3.7072e-01, -1.3141e-01, -5.2504e-01, -5.6775e-01, -1.6822e-01,\n",
            "        -9.1726e-02,  8.1418e-02,  4.5884e-02, -1.4401e+00, -1.6349e-01,\n",
            "         4.9361e-01,  2.1410e-01, -7.0110e-01,  2.3067e-01, -1.1803e+00,\n",
            "         6.5701e-02, -4.6429e-02,  8.0979e-02, -1.6424e-01, -7.2896e-01,\n",
            "        -2.1221e-01,  3.4235e-02, -4.0642e-01,  2.8826e-01, -8.1331e-01,\n",
            "        -6.7997e-02, -2.5439e-01,  1.3735e-01,  1.0103e+00, -7.7614e-01])\n",
            "Token[6]: \"the\"\n",
            "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
            "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
            "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
            "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
            "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
            "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
            "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
            "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
            "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
            "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
            "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
            "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
            "        -0.5203, -0.1459,  0.8278,  0.2706])\n",
            "Token[7]: \"garden\"\n",
            "tensor([-0.2232,  0.4870,  0.0331,  0.2905,  0.4769,  0.4677,  0.0872,  0.4971,\n",
            "        -0.4884, -0.1149, -0.4174, -0.1308, -0.1250, -0.2501, -0.0954,  0.2517,\n",
            "         0.5717,  0.8413, -0.7517, -0.1259, -0.6368, -0.0148, -0.1341, -0.3983,\n",
            "         0.7498,  0.0643,  0.2457, -0.5223, -0.3843,  0.0123, -0.8849,  0.1009,\n",
            "         0.9215, -0.1627,  0.0020,  0.8685, -0.2653, -0.0872,  0.2198, -0.7844,\n",
            "         0.6399, -0.9277,  0.0142, -0.4827,  0.9809, -0.1873, -0.6377,  0.3228,\n",
            "         0.6526, -0.3110,  0.0122, -0.9677,  0.7712,  0.4064, -0.2810, -1.8811,\n",
            "         0.0100,  0.2800,  0.7884,  0.1294, -0.0264,  1.3719, -0.0355,  0.3390,\n",
            "         0.7847, -0.2632,  0.4405, -0.1808,  0.4482, -0.5597, -0.6184,  0.2233,\n",
            "        -0.1754, -0.8932, -0.4209, -0.3024,  0.7570,  0.5630, -0.4328,  0.8242,\n",
            "         0.1144,  0.2006, -0.2840,  0.4263, -0.0415,  0.0678, -0.1226, -0.2472,\n",
            "         0.3068,  0.8167,  0.4497, -1.0171,  0.8771,  0.3582, -0.5985, -0.1731,\n",
            "        -0.4304, -0.4437,  0.8132,  0.8075])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The embedding of the word rose as a flower\")\n",
        "print(sentence1[4].embedding)\n",
        "print(\"Size of that embedding \",len(sentence1[4].embedding))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OzsBV8aKv_C",
        "outputId": "5dd62756-261b-4a32-d906-c76143a63163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The embedding of the word rose as a flower\n",
            "tensor([ 1.0937,  0.8214, -0.1852,  0.0786,  0.4147, -0.6426,  0.4255, -0.4695,\n",
            "        -0.4304, -0.4947, -0.0741, -0.4623, -0.3771, -0.2303,  0.6403, -0.5667,\n",
            "        -0.2091,  0.1569,  0.1502,  0.4576,  1.1152, -0.1295,  0.6497,  1.2699,\n",
            "         0.4033, -0.2435,  0.1815, -0.6812,  0.0251, -0.2500,  0.2702, -0.3044,\n",
            "         0.0668,  0.0367, -0.0932,  1.1323,  1.0154,  0.0239,  0.2471, -0.2042,\n",
            "         0.0470, -1.1112, -0.2564, -0.3373,  0.3545,  0.6022, -0.6253,  0.4094,\n",
            "         0.5817, -1.9538,  0.0367, -0.2600,  0.5758,  1.3510, -0.3376, -1.7692,\n",
            "        -0.7869,  0.1131,  1.3780,  0.7508,  0.4910, -0.2592, -0.7883,  0.1579,\n",
            "        -0.9344, -0.0443,  0.5513,  0.4390,  1.4439,  0.5425, -0.2027,  0.2897,\n",
            "        -0.4371,  0.1773, -0.3873,  0.3120, -0.0888,  0.3427, -0.6611,  0.1731,\n",
            "         0.2724,  0.6642, -0.2498, -0.4517, -0.4424, -0.7880,  0.3900, -0.6051,\n",
            "         1.1775,  0.6952,  0.3008, -0.0824, -0.4513,  0.4200, -1.2335,  0.4458,\n",
            "         0.1206, -0.3677,  0.1822,  0.3347])\n",
            "Size of that embedding  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create sentence for rose as a ver verb means rising in the past.\n",
        "sentence2 = Sentence('The price of the stocks rose sharply in the market.')\n",
        "\n",
        "print(sentence2)\n",
        "print(sentence2.tokens)\n",
        "\n",
        "print(sentence2[5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQDrtTDWoR5N",
        "outputId": "9865e335-6562-4d4e-c993-ca1b5854b488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence[11]: \"The price of the stocks rose sharply in the market.\"\n",
            "[Token[0]: \"The\", Token[1]: \"price\", Token[2]: \"of\", Token[3]: \"the\", Token[4]: \"stocks\", Token[5]: \"rose\", Token[6]: \"sharply\", Token[7]: \"in\", Token[8]: \"the\", Token[9]: \"market\", Token[10]: \".\"]\n",
            "Token[5]: \"rose\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embedding.embed(sentence2)\n",
        "\n",
        "for token in sentence2:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOrffUV7LxFK",
        "outputId": "df09e3e2-0422-4854-c2ac-ae81230f18b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[0]: \"The\"\n",
            "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
            "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
            "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
            "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
            "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
            "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
            "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
            "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
            "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
            "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
            "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
            "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
            "        -0.5203, -0.1459,  0.8278,  0.2706])\n",
            "Token[1]: \"price\"\n",
            "tensor([ 3.3108e-01,  1.9364e-01,  1.6607e-01,  8.6574e-02, -2.0639e-01,\n",
            "        -1.4334e+00, -2.9923e-01, -1.1618e-01, -6.6627e-01, -1.4150e-01,\n",
            "         2.1907e-01,  1.6721e-01, -1.6150e-01, -2.8570e-01,  2.7179e-01,\n",
            "         9.5956e-02, -9.7168e-01,  1.0444e-01,  1.0485e-01,  1.3673e-01,\n",
            "         8.3398e-01, -6.8866e-01,  2.6409e-01,  2.9890e-01,  5.9473e-01,\n",
            "         1.4549e-02,  1.7850e-02, -9.5206e-01, -6.6171e-01, -2.2428e-01,\n",
            "         3.2354e-01,  5.7278e-01, -7.1502e-02, -1.4367e-01,  3.1574e-01,\n",
            "         7.4511e-01,  7.5837e-01, -1.7850e-03,  1.0807e-01, -9.9260e-01,\n",
            "         2.5383e-01, -5.2487e-01, -1.3455e-01, -3.1672e-01,  3.7978e-02,\n",
            "         4.0723e-01, -5.5722e-01, -1.0508e+00,  5.0940e-03, -1.4605e+00,\n",
            "         8.2840e-01, -1.4003e-01, -9.2980e-03,  8.4426e-01, -2.6589e-01,\n",
            "        -2.1714e+00, -5.7227e-02, -1.6759e-01,  2.0411e+00, -2.6865e-01,\n",
            "         4.3311e-01, -4.7494e-01, -8.3282e-01,  4.2100e-01,  3.4240e-01,\n",
            "        -5.1296e-01,  6.7027e-01, -2.9009e-01,  7.7592e-01, -1.8930e-01,\n",
            "        -4.4136e-01, -6.3027e-02, -2.9517e-01,  5.3799e-01, -8.2541e-02,\n",
            "        -2.5948e-01,  3.1671e-01, -4.3428e-02, -1.1532e+00,  3.7127e-01,\n",
            "         8.3853e-01,  1.9424e-01, -4.1475e-01, -9.4061e-01, -6.8660e-01,\n",
            "        -8.6623e-01, -4.4902e-01, -6.0698e-01,  7.7263e-02, -1.6278e-01,\n",
            "        -4.3910e-01,  4.3965e-01, -1.7207e-01, -6.6014e-01, -1.2322e+00,\n",
            "         1.6748e-01,  7.3098e-01, -3.3899e-01,  5.9354e-01, -1.6754e-02])\n",
            "Token[2]: \"of\"\n",
            "tensor([-0.1529, -0.2428,  0.8984,  0.1700,  0.5352,  0.4878, -0.5883, -0.1798,\n",
            "        -1.3581,  0.4254,  0.1538,  0.2421,  0.1347,  0.4119,  0.6704, -0.5642,\n",
            "         0.4299, -0.0122, -0.1168,  0.3178,  0.0542, -0.0543,  0.3552, -0.3024,\n",
            "         0.3143, -0.3385,  0.7171, -0.2686, -0.1584, -0.4747,  0.0516, -0.3325,\n",
            "         0.1500, -0.1299, -0.5462, -0.3784,  0.6426,  0.8219, -0.0800,  0.0785,\n",
            "        -0.9698, -0.5774,  0.5649, -0.3987, -0.0571,  0.1974,  0.0657, -0.4809,\n",
            "        -0.2013, -0.4083,  0.3946, -0.0264, -0.1184,  1.0120, -0.5317, -2.7474,\n",
            "        -0.0430, -0.7485,  1.7574,  0.5908,  0.0488,  0.7827,  0.3850,  0.4210,\n",
            "         0.6788,  0.1034,  0.6328, -0.0266,  0.5865, -0.4433,  0.3306, -0.1202,\n",
            "        -0.5565,  0.0736,  0.2092,  0.4340, -0.0128,  0.0899, -1.7991,  0.0848,\n",
            "         0.7711,  0.6310, -0.9068,  0.6033, -1.7515,  0.1860, -0.5069, -0.7020,\n",
            "         0.6658, -0.8130,  0.1871, -0.0185, -0.2676,  0.7270, -0.5936, -0.3484,\n",
            "        -0.5609, -0.5910,  1.0039,  0.2066])\n",
            "Token[3]: \"the\"\n",
            "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
            "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
            "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
            "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
            "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
            "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
            "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
            "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
            "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
            "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
            "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
            "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
            "        -0.5203, -0.1459,  0.8278,  0.2706])\n",
            "Token[4]: \"stocks\"\n",
            "tensor([ 0.5044,  1.6584,  0.4449,  0.1103, -0.2617, -1.6535, -0.5356, -0.8892,\n",
            "        -0.3499, -1.6128,  0.2677,  0.0268, -0.0246, -0.6453, -0.3672, -0.0102,\n",
            "        -0.4610, -0.1109,  0.8014, -0.1487,  1.3536, -0.3146,  0.3261,  0.8113,\n",
            "        -0.2664, -0.5293,  0.0069, -0.4657, -1.0183,  0.2463, -0.2162, -0.1034,\n",
            "        -1.3928,  0.4735,  0.0518,  0.3555,  0.5480, -0.8690, -0.0576, -0.1983,\n",
            "         0.3973, -1.3323, -0.6006, -0.3612,  0.2421,  0.2379, -0.2614,  0.5079,\n",
            "        -0.0787, -2.0572, -0.6778,  0.6553,  0.3200,  0.5412, -0.7693, -1.2558,\n",
            "        -0.2986, -0.1903,  2.2076,  0.3943, -0.5412,  0.1401, -0.0746,  0.4803,\n",
            "        -0.4374,  0.4915,  1.0216,  0.0485,  1.0091,  0.3496, -0.7171,  0.2368,\n",
            "        -0.4825, -0.0368, -0.7687, -0.0040, -0.6500,  0.6039, -0.6744, -0.1405,\n",
            "         1.0805,  0.2496, -1.0785,  0.1616, -0.6611, -1.1331,  0.1444, -0.6983,\n",
            "         0.1517, -0.3022, -0.3169,  0.0872, -0.1453, -0.1364, -1.5364,  0.9865,\n",
            "         0.5740, -0.4056,  0.0948,  0.6332])\n",
            "Token[5]: \"rose\"\n",
            "tensor([ 1.0937,  0.8214, -0.1852,  0.0786,  0.4147, -0.6426,  0.4255, -0.4695,\n",
            "        -0.4304, -0.4947, -0.0741, -0.4623, -0.3771, -0.2303,  0.6403, -0.5667,\n",
            "        -0.2091,  0.1569,  0.1502,  0.4576,  1.1152, -0.1295,  0.6497,  1.2699,\n",
            "         0.4033, -0.2435,  0.1815, -0.6812,  0.0251, -0.2500,  0.2702, -0.3044,\n",
            "         0.0668,  0.0367, -0.0932,  1.1323,  1.0154,  0.0239,  0.2471, -0.2042,\n",
            "         0.0470, -1.1112, -0.2564, -0.3373,  0.3545,  0.6022, -0.6253,  0.4094,\n",
            "         0.5817, -1.9538,  0.0367, -0.2600,  0.5758,  1.3510, -0.3376, -1.7692,\n",
            "        -0.7869,  0.1131,  1.3780,  0.7508,  0.4910, -0.2592, -0.7883,  0.1579,\n",
            "        -0.9344, -0.0443,  0.5513,  0.4390,  1.4439,  0.5425, -0.2027,  0.2897,\n",
            "        -0.4371,  0.1773, -0.3873,  0.3120, -0.0888,  0.3427, -0.6611,  0.1731,\n",
            "         0.2724,  0.6642, -0.2498, -0.4517, -0.4424, -0.7880,  0.3900, -0.6051,\n",
            "         1.1775,  0.6952,  0.3008, -0.0824, -0.4513,  0.4200, -1.2335,  0.4458,\n",
            "         0.1206, -0.3677,  0.1822,  0.3347])\n",
            "Token[6]: \"sharply\"\n",
            "tensor([-0.0331,  0.4697, -0.1511,  0.6403,  0.4202, -0.6946, -0.9818, -0.2402,\n",
            "         0.3279, -0.0571, -0.9693, -0.0841,  0.1101, -0.7980,  0.4073,  0.1643,\n",
            "        -1.5320, -0.4390, -0.0980, -0.6414,  1.4306, -0.2036,  0.6254,  1.3579,\n",
            "         0.0193, -0.1612, -0.9129, -0.2644, -0.2807,  0.2981,  0.8533,  0.2088,\n",
            "        -0.6489, -0.1081, -0.2703,  0.9205,  0.1801, -0.2302, -0.8358,  0.4807,\n",
            "        -0.4195, -0.8911, -0.3100,  0.5416,  0.0597, -0.2655,  0.4508,  0.4871,\n",
            "         0.4233, -1.5076,  0.8014, -0.0959,  0.2215,  1.5041, -0.6311, -1.3070,\n",
            "         0.1749,  0.0182,  1.2363,  0.3338,  0.2192,  0.1548,  0.1613, -0.2587,\n",
            "        -0.5369,  0.0306,  0.0774,  0.4305,  0.7654,  0.4951, -0.0900,  0.0632,\n",
            "        -0.1925,  0.1013, -0.0465, -0.5743, -0.5157,  0.4388, -0.2320, -0.2951,\n",
            "        -0.0381,  0.3012, -0.4584, -0.5160, -0.6773, -1.1222,  0.0809, -0.0377,\n",
            "        -0.5295, -0.2118, -0.2680,  0.1890, -1.3154, -0.0048, -0.3710,  0.5985,\n",
            "         0.0891,  0.4420,  0.3909, -0.0791])\n",
            "Token[7]: \"in\"\n",
            "tensor([ 0.0857, -0.2220,  0.1657,  0.1337,  0.3824,  0.3540,  0.0129,  0.2246,\n",
            "        -0.4382,  0.5016, -0.3587, -0.3498,  0.0552,  0.6965, -0.1796,  0.0679,\n",
            "         0.3910,  0.1604, -0.2664, -0.2114,  0.5370,  0.4938,  0.9366,  0.6690,\n",
            "         0.2179, -0.4664,  0.2238, -0.3620, -0.1766,  0.1748, -0.2037,  0.1393,\n",
            "         0.0198, -0.1041, -0.2024,  0.5500, -0.1546,  0.9865, -0.2686, -0.2909,\n",
            "        -0.3287, -0.3419, -0.1694, -0.4200, -0.0467, -0.1633,  0.7082, -0.7491,\n",
            "        -0.0916, -0.9618, -0.1975,  0.1028,  0.5522,  1.3816, -0.6564, -3.2502,\n",
            "        -0.3156, -1.2055,  1.7709,  0.4026, -0.7983,  1.1597, -0.3304,  0.3138,\n",
            "         0.7739,  0.2260,  0.5247, -0.0341,  0.3205,  0.0799,  0.1775, -0.4943,\n",
            "        -0.7005, -0.4457,  0.1724,  0.2028,  0.0233, -0.2068, -1.0158,  0.1832,\n",
            "         0.5675,  0.3182, -0.6501,  0.6828, -0.8658, -0.0594, -0.2926, -0.5567,\n",
            "        -0.3471, -0.3289,  0.4022, -0.1275, -0.2023,  0.8737, -0.5450,  0.7921,\n",
            "        -0.2069, -0.0743,  0.7581, -0.3424])\n",
            "Token[8]: \"the\"\n",
            "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
            "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
            "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
            "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
            "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
            "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
            "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
            "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
            "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
            "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
            "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
            "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
            "        -0.5203, -0.1459,  0.8278,  0.2706])\n",
            "Token[9]: \"market\"\n",
            "tensor([ 0.3909,  0.2376,  0.4485,  0.1124, -0.2600, -1.2248, -0.4424, -0.5349,\n",
            "         0.3714, -0.6198, -0.2739, -0.0322,  0.0826, -0.5299,  0.1301,  0.2170,\n",
            "        -0.4503, -0.0049,  0.3489, -0.2607,  0.5660, -0.3622,  0.4193,  0.2344,\n",
            "        -0.2941, -0.2704,  0.2934, -0.7390, -0.7596,  0.6466, -0.0388,  0.3850,\n",
            "        -0.3231,  0.0403,  0.2404,  0.3517,  0.4740,  0.0150,  0.1211, -1.0398,\n",
            "         0.2764, -1.3785, -0.2285, -0.0981,  0.1495, -0.2815,  0.3168, -0.1021,\n",
            "        -0.0859, -1.5114, -0.4825,  0.1513,  0.0080,  0.7459, -0.2016, -2.5268,\n",
            "        -0.8208,  0.1143,  2.4665,  0.1984,  0.1146,  0.1008, -0.6094,  0.7672,\n",
            "         0.0260, -0.0369,  0.4674, -0.7707,  0.8399, -0.0329, -0.1313, -0.0974,\n",
            "        -0.4263, -0.4948, -0.4080, -0.6750, -0.2853,  0.1247, -1.1450, -0.4306,\n",
            "         1.1720,  0.4075, -0.8309,  0.4168, -0.8302, -0.8872, -0.5983, -0.5665,\n",
            "        -0.2275, -0.4240,  0.6338,  0.6204, -0.1343, -0.4901, -0.7836,  0.8584,\n",
            "         0.6010, -0.4060,  0.7783,  1.1050])\n",
            "Token[10]: \".\"\n",
            "tensor([-0.3398,  0.2094,  0.4635, -0.6479, -0.3838,  0.0380,  0.1713,  0.1598,\n",
            "         0.4662, -0.0192,  0.4148, -0.3435,  0.2687,  0.0446,  0.4213, -0.4103,\n",
            "         0.1546,  0.0222, -0.6465,  0.2526,  0.0431, -0.1945,  0.4652,  0.4565,\n",
            "         0.6859,  0.0913,  0.2188, -0.7035,  0.1679, -0.3508, -0.1263,  0.6638,\n",
            "        -0.2582,  0.0365, -0.1361,  0.4025,  0.1429,  0.3813, -0.1228, -0.4589,\n",
            "        -0.2528, -0.3043, -0.1121, -0.2618, -0.2248, -0.4455,  0.2991, -0.8561,\n",
            "        -0.1450, -0.4909,  0.0083, -0.1749,  0.2752,  1.4401, -0.2124, -2.8435,\n",
            "        -0.2796, -0.4572,  1.6386,  0.7881, -0.5526,  0.6500,  0.0864,  0.3901,\n",
            "         1.0632, -0.3538,  0.4833,  0.3460,  0.8417,  0.0987, -0.2421, -0.2705,\n",
            "         0.0453, -0.4015,  0.1139,  0.0062,  0.0367,  0.0185, -1.0213, -0.2081,\n",
            "         0.6407, -0.0688, -0.5864,  0.3348, -1.1432, -0.1148, -0.2509, -0.4591,\n",
            "        -0.0968, -0.1795, -0.0634, -0.6741, -0.0689,  0.5360, -0.8777,  0.3180,\n",
            "        -0.3924, -0.2339,  0.4730, -0.0288])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The embedding of the word rose as a verb means rising\")\n",
        "print(sentence2[5].embedding)\n",
        "print(\"Size of that embedding \",len(sentence2[5].embedding))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddLjn8HIL7Z6",
        "outputId": "c94d10a6-3584-43fc-a3ba-aae31c899932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The embedding of the word rose as a verb means rising\n",
            "tensor([ 1.0937,  0.8214, -0.1852,  0.0786,  0.4147, -0.6426,  0.4255, -0.4695,\n",
            "        -0.4304, -0.4947, -0.0741, -0.4623, -0.3771, -0.2303,  0.6403, -0.5667,\n",
            "        -0.2091,  0.1569,  0.1502,  0.4576,  1.1152, -0.1295,  0.6497,  1.2699,\n",
            "         0.4033, -0.2435,  0.1815, -0.6812,  0.0251, -0.2500,  0.2702, -0.3044,\n",
            "         0.0668,  0.0367, -0.0932,  1.1323,  1.0154,  0.0239,  0.2471, -0.2042,\n",
            "         0.0470, -1.1112, -0.2564, -0.3373,  0.3545,  0.6022, -0.6253,  0.4094,\n",
            "         0.5817, -1.9538,  0.0367, -0.2600,  0.5758,  1.3510, -0.3376, -1.7692,\n",
            "        -0.7869,  0.1131,  1.3780,  0.7508,  0.4910, -0.2592, -0.7883,  0.1579,\n",
            "        -0.9344, -0.0443,  0.5513,  0.4390,  1.4439,  0.5425, -0.2027,  0.2897,\n",
            "        -0.4371,  0.1773, -0.3873,  0.3120, -0.0888,  0.3427, -0.6611,  0.1731,\n",
            "         0.2724,  0.6642, -0.2498, -0.4517, -0.4424, -0.7880,  0.3900, -0.6051,\n",
            "         1.1775,  0.6952,  0.3008, -0.0824, -0.4513,  0.4200, -1.2335,  0.4458,\n",
            "         0.1206, -0.3677,  0.1822,  0.3347])\n",
            "Size of that embedding  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity= 1- spatial.distance.cosine(sentence1[4].embedding,sentence2[5].embedding)\n",
        "if(similarity):\n",
        "    print(\"There is no difference between rose as a verb meaning rise and rose as a flower:(\")\n",
        "else:\n",
        "  print(\"rose as a verb meaning rise and rose as a flower are different:)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY0iVPyjpvkA",
        "outputId": "738b97e1-ffbc-43a0-96ac-72bfe8239957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is no difference between rose as a verb meaning rise and rose as a flower:(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can conclude that glove doesn't work on contextual meaning but as a same word or not"
      ],
      "metadata": {
        "id": "0vshkrf_Oi2P"
      }
    }
  ]
}